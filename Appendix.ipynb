{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8551c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f23dcb6-480f-4d10-8609-063999ded7a6",
   "metadata": {},
   "source": [
    "### Original df_loc (Canada) Description\n",
    "\n",
    "[Statistics Canada](https://www.statcan.gc.ca/eng/start) provides several geographic divisions for reporting of census statistics:\n",
    "\n",
    "Dissemination Area: DAs are small, relatively stable geographic unit composed of one or more adjacent dissemination blocks with an average population of 400 to 700 persons based on data from the previous Census of Population Program. It is the smallest standard geographic area for which all census data are disseminated.\n",
    "\n",
    "Aggregate Dissemination Area: ADAs cover the entire country and, where possible, have a population count between 5,000 and 15,000 people, and respect provincial, territorial, census division (CD), census metropolitan area (CMA) and census agglomeration (CA) with census tract (CT) boundaries in effect for the 2016 Census.\n",
    "\n",
    "Census Tract: CTs are small, relatively stable geographic areas that usually have a population of less than 10,000 persons, based on data from the previous Census of Population Program. They are located in census metropolitan areas and in census agglomerations that had a core population of 50,000 or more in the previous census.\n",
    "\n",
    "Census Metropolitan Area/ Census Agglomeration: A CMA or CA is formed by one or more adjacent municipalities centred on a population centre (known as the core). A CMA must have a total population of at least 100,000 of which 50,000 or more must live in the core based on adjusted data from the previous Census of Population Program. A CA must have a core population of at least 10,000 also based on data from the previous Census of Population Program. To be included in the CMA or CA, other adjacent municipalities must have a high degree of integration with the core, as measured by commuting flows derived from data on place of work from the previous Census Program.\n",
    "\n",
    "Census Subdivision: CSD is the general term for municipalities (as determined by provincial/territorial legislation) or areas treated as municipal equivalents for statistical purposes (e.g., Indian reserves, Indian settlements and unorganized territories).\n",
    "\n",
    "Census Consolidated Subdivision:A CCS is a group of adjacent census subdivisions within the same census division. Generally, the smaller, more densely-populated census subdivisions (towns, villages, etc.) are combined with the surrounding, larger, more rural census subdivision, in order to create a geographic level between the census subdivision and the census division.\n",
    "\n",
    "Census Division: CDs are a group of neighbouring municipalities joined together for the purposes of regional planning and managing common services (such as police or ambulance services).  Census divisions are intermediate geographic areas between the province/territory level and the municipality (census subdivision).\n",
    "\n",
    "Economic Region: An ER is a grouping of complete census divisions (CDs), with one exception in Ontario, created as a standard geographic unit for analysis of regional economic activity.\n",
    "\n",
    "Note: CSDNAME = 'Toronto' gives the same area as the FSAs, which makes sense as this is probably the definition of 'Toronto' \n",
    "\n",
    "The meaning of prefixes for NAME (N), UID (U), PUID (PU), TYPE (T), and CODE (C):\n",
    "* DA U Dissemination Area unique identifier (composed of the 2-digit province/territory unique identifier followed by the 2-digit census division code and the 4-digit dissemination area code)\n",
    "* PR U,N Province or territory\n",
    "* CD U,N,T Census Division\n",
    "* CCS U,N Census Consolidated Subdivision\n",
    "* CSD U,N,T Census Subdivision\n",
    "* ER U,N Economic Region\n",
    "* SAC T,C Statistical Area Classification: Part of are a component of a census metropolitan area, a census agglomeration, a census metropolitan influenced zone or the territories?\n",
    "* CMA U,PU,N,T Census Metropolitan Area or Census Agglomeration name, PU Uniquely identifies the provincial or territorial part of a census metropolitan area or census agglomeration (composed of the 2-digit province or territory unique identifier followed by the 3-digit census metropolitan area or census agglomeration unique identifier)\n",
    "* CT U,N Census Tract within census metropolitan area/census agglomeration\n",
    "* ADA U Aggregate dissemination area unique identifier\n",
    "\n",
    "We will use census Distribution Areas as proxies for neighborhoods for cities in Canada.  In previous work where the Forward Sortation Areas (first three characters of the postal code) were used as neighborhood proxies, the sizes of many areas were quite large (several kilometers across) and therefore are likely internally non-homogeneous from a features perspective at the walking-distance (500 m) length scale.  To convert to neighborhood names we can look up the associated census tract as seen on [this](https://en.wikipedia.org/wiki/Demographics_of_Toronto_neighbourhoods) Wikipedia page.\n",
    "\n",
    "File lda_000b16g_e.gml was downloaded from the [Statistics Canada: Boundary Files](https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2016-eng.cfm) site.\n",
    "\n",
    "Exploring the gml file and computing the area and centroid of the distribution areas can be done using the [geopandas module](https://geopandas.org/).  Geopandas builds upon [osgeo](https://gdal.org/python/index.html) which can also be used to explore and compute with the gml file, but in testing was 46 times faster due to vectorization of many calculations compared to a naive approach (see Appendix).\n",
    "\n",
    "Latitude and Longitude need to be obtained from a projection with those units, e.g. [EPSG-4326](https://epsg.io/4326).  Area can be calculated from an equal-area projection, e.g. [EPSG-6931](https://epsg.io/6931) (though a geodesic area calculation would be more accurate for larger regions, that would have to come from an additional package such as [proj](https://proj.org/), but since all regions here are small such the curvature of the earth is negligible, and altitude indtroduces an additional error likely comparable or larger to the curvature error, we will proceed with a simpler equal-area projection calculation).  The geometry is saved as text in the [Well-Known Text (WKT)](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67709d2-92ed-4d73-a510-117f47fb700b",
   "metadata": {},
   "source": [
    "# Original Cities_Compared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5531d1-1a94-482c-88f4-e4b45c7f9de0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cities compared:\n",
    "* Canada\n",
    "    * Toronto\n",
    "    * Montr√©al\n",
    "    * Vancouver\n",
    "    * Halifax\n",
    "* United States of America\n",
    "    * New York City\n",
    "    * Boston\n",
    "    * Chicago\n",
    "    * San Fransisco\n",
    "* France\n",
    "    * Paris\n",
    "* England\n",
    "    * London\n",
    "\n",
    "First, get a list of Forward Sortation Areas as proxies for neighborhoods for cities in Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc60383-a8c5-4061-b00e-5d832278f731",
   "metadata": {},
   "source": [
    "# Original parsing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7550859-737f-4470-89fe-bce2df34b40e",
   "metadata": {},
   "source": [
    "### Osgeo package\n",
    "\n",
    "Before finding the geopandas library, I was using [gdal](https://gdal.org/python/index.html) (which is one of many dependencies of geopandas).  Using gdal's ogr and osr modules in the osgeo package I read in the gml file, converted coordinates to accurately compute area, and converted coordinates again to latitude and longitude.  As a guide to learning the library I adapted code from some [examples](https://pcjericks.github.io/py-gdalogr-cookbook/geometry.html#quarter-polygon-and-create-centroids).  Conversion to geojson may be done explicitly as demonstrated [here](https://gis.stackexchange.com/questions/77974/converting-gml-to-geojson-using-python-and-ogr-with-geometry-transformation), but by the time I was going to convert to geojson I found it much easier with geopandas, and this approach was abandoned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a91fec-052e-45d7-9651-03ce4989c02b",
   "metadata": {},
   "source": [
    "#### Parsing GML file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76403f1-15b9-4e93-a32d-74b8b7e22f3d",
   "metadata": {},
   "source": [
    "    from osgeo import ogr\n",
    "    from osgeo import osr\n",
    "    \n",
    "    def parseGMLtoDF(fn_gml,limit=None):\n",
    "        '''Reads in a GML file and outputs a DataFrame\n",
    "\n",
    "        Adds columns for Geometry (in WKT format), Latitude (of centroid), Longitude (of centroid) and Area (in square meters)\n",
    "        '''\n",
    "        # Add lightweight progress bar, source copied from GitHub\n",
    "        import ipypb\n",
    "\n",
    "        # Read in the file\n",
    "        source = ogr.Open(fn_gml)\n",
    "        layer = source.GetLayer(0) # there is only one Layer (the FeatureCollection)\n",
    "\n",
    "        # Get a list of field names to extract (also could be gotten from schema e.g. lda_000b16g_e.xsd)\n",
    "        #   Fields are in order (sequence) and none are required (minOccurs=0)\n",
    "        layerDefinition = layer.GetLayerDefn()\n",
    "        layerFields = [layerDefinition.GetFieldDefn(i).GetName() for i in range(layerDefinition.GetFieldCount())]\n",
    "\n",
    "        # Initialize the output dataframe\n",
    "        df = pd.DataFrame(columns=[*layerFields, 'Geometry', 'Latitude', 'Longitude', 'Area'])\n",
    "\n",
    "        # Extract data from the features\n",
    "        parse_limit = layer.GetFeatureCount()\n",
    "        if not limit is None:\n",
    "            parse_limit = limit\n",
    "\n",
    "        for i in ipypb.track(range(parse_limit)):\n",
    "            # Get the feature to be processed\n",
    "            feature = layer.GetNextFeature()\n",
    "\n",
    "            # Copy all fields into an empty dataframe\n",
    "            df_tmp = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "            # Copy all fields individually, in case some are missing\n",
    "            for i, fieldname in enumerate(layerFields):\n",
    "                if feature.IsFieldSet(i):\n",
    "                    df_tmp.loc[0,fieldname] = feature.GetFieldAsString(fieldname)\n",
    "\n",
    "            # Get the latitude and longitude\n",
    "            inref = feature.GetGeometryRef().GetSpatialReference() # EPSG 3347\n",
    "            llref = osr.SpatialReference()\n",
    "            llref.ImportFromEPSG(4326) # coordinates for this geometry are latitude, longitude\n",
    "            lltransform = osr.CoordinateTransformation(inref, llref)\n",
    "            geom = feature.GetGeometryRef().Clone()\n",
    "            geom.Transform(lltransform)\n",
    "            centroid = geom.Centroid()\n",
    "            df_tmp['Latitude'] = centroid.GetX()\n",
    "            df_tmp['Longitude'] = centroid.GetY()\n",
    "            df_tmp['Geometry'] = geom.ExportToWkt()\n",
    "\n",
    "            # Get the area by converting to a locally-appropriate coordinate system\n",
    "            inref = feature.GetGeometryRef().GetSpatialReference()\n",
    "            arref = osr.SpatialReference()\n",
    "            arref.ImportFromEPSG(6931) # TODO: let this choose appropriate projection based on centroid for full-globe applicability, or alter to be a geodesic calculation.  Lambert Cylindrical Equal Area 6933, U.S. National Atlas Equal Area Projection 2163, NSIDC EASE-Grid North 3408, WGS 84 / NSIDC EASE-Grid 2.0 North 6931, WGS 84 / NSIDC EASE-Grid 2.0 South 6932, WGS 84 / NSIDC EASE-Grid 2.0 Global/Temperate 6933\n",
    "            artransform = osr.CoordinateTransformation(inref, arref)\n",
    "            geom = feature.GetGeometryRef().Clone() # Fresh instance to prevent error accumulation from multiple transforms\n",
    "            geom.Transform(artransform)\n",
    "            df_tmp['Area'] = geom.Area() # TODO: investigate proj module, related to osgeo, for geodesic area\n",
    "\n",
    "            # Add the feature dataframe to the output\n",
    "            df = df.append(df_tmp, ignore_index=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94eb29c-f035-417a-b075-85dfee105117",
   "metadata": {},
   "source": [
    "#### Viewing fields\n",
    "\n",
    "    layerDefinition = s2.GetLayerDefn()\n",
    "\n",
    "    for i in range(layerDefinition.GetFieldCount()):\n",
    "        print(layerDefinition.GetFieldDefn(i).GetName(),f\" \\t\",s2.GetFeature(0).GetFieldAsString(s2.GetFeature(0).GetFieldIndex(layerDefinition.GetFieldDefn(i).GetName())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc851e-4996-41a0-ad78-c2b2372394ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA_DA = parseGMLtoDF('lda_000b16g_e.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43e3a9-3748-4446-8418-8c5235dea7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_CA_DA.head(2))\n",
    "print(df_CA_DA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500ab87-48ed-4d51-ad1f-320a7a53c94f",
   "metadata": {},
   "source": [
    "#### Layered parsing code\n",
    "\n",
    "From when I thought dataframe copying was the limiting step\n",
    "\n",
    "    # Read in the file\n",
    "    source = ogr.Open('lda_000b16g_e.gml')\n",
    "    layer = source.GetLayer(0) # there is only one Layer (the FeatureCollection)\n",
    "\n",
    "    # Get a list of field names to extract (see lda_000b16g_e.xsd)\n",
    "    #   Fields are in order (sequence) and none are required (minOccurs=0)\n",
    "    layerDefinition = layer.GetLayerDefn()\n",
    "    layerFields = [layerDefinition.GetFieldDefn(i).GetName() for i in range(layerDefinition.GetFieldCount())]\n",
    "\n",
    "    %%time\n",
    "    import ipypb # Lightweight progress bar, source copied from GitHub\n",
    "\n",
    "    # Initialize the output dataframe - REUSE FOR ALL OF CANADA\n",
    "    df_CA_DA = pd.DataFrame(columns=[*layerFields, 'Geometry', 'Latitude', 'Longitude', 'Area'])\n",
    "\n",
    "    # Only process a few entries\n",
    "    parse_limit = 5\n",
    "\n",
    "    # Setup for 2-step dataframe appending, should be ~O(n^(1+e)) instead of ~O(n^2)\n",
    "    n_features = layer.GetFeatureCount()\n",
    "    #max_n_merge = 1000\n",
    "    n_merge = n_features**0.5//1\n",
    "    #n_merge = min(n_features**0.5//1,max_n_merge) # How many rows to process before a merge\n",
    "    df_tmp_collect = pd.DataFrame(columns=df_CA_DA.columns)\n",
    "\n",
    "    # Extract data from the features\n",
    "    layer.ResetReading()\n",
    "    for i in ipypb.track(range(layer.GetFeatureCount())):\n",
    "        # Get the feature to be processed\n",
    "        feature = layer.GetNextFeature()\n",
    "\n",
    "        # Copy all fields into an empty dataframe\n",
    "        df_tmp = pd.DataFrame(columns=df_CA_DA.columns)\n",
    "\n",
    "        # Copy all fields individually, in case some are missing\n",
    "        for i, fieldname in enumerate(layerFields):\n",
    "            if feature.IsFieldSet(i):\n",
    "                df_tmp.loc[0,fieldname] = feature.GetFieldAsString(fieldname)\n",
    "\n",
    "        # Get the latitude and longitude\n",
    "        inref = feature.GetGeometryRef().GetSpatialReference() # EPSG 3347\n",
    "        llref = osr.SpatialReference()\n",
    "        llref.ImportFromEPSG(4326) # coordinates for this geometry are latitude, longitude\n",
    "        lltransform = osr.CoordinateTransformation(inref, llref)\n",
    "        geom = feature.GetGeometryRef().Clone()\n",
    "        geom.Transform(lltransform)\n",
    "        centroid = geom.Centroid()\n",
    "        df_tmp['Latitude'] = centroid.GetX()\n",
    "        df_tmp['Longitude'] = centroid.GetY()\n",
    "        df_tmp['Geometry'] = geom.ExportToWkt()\n",
    "\n",
    "        # Get the area by converting to a locally-appropriate coordinate system\n",
    "        inref = feature.GetGeometryRef().GetSpatialReference()\n",
    "        arref = osr.SpatialReference()\n",
    "        arref.ImportFromEPSG(6931) # Lambert Cylindrical Equal Area 6933, U.S. National Atlas Equal Area Projection 2163, NSIDC EASE-Grid North 3408, WGS 84 / NSIDC EASE-Grid 2.0 North 6931, WGS 84 / NSIDC EASE-Grid 2.0 South 6932, WGS 84 / NSIDC EASE-Grid 2.0 Global/Temperate 6933\n",
    "        artransform = osr.CoordinateTransformation(inref, arref)\n",
    "        geom = feature.GetGeometryRef().Clone() # Fresh instance to prevent error accumulation from multiple transforms\n",
    "        geom.Transform(artransform)\n",
    "        df_tmp['Area'] = geom.Area()\n",
    "\n",
    "        # Add the feature dataframe to the output\n",
    "        #df_tmp_collect = df_tmp_collect.append(df_tmp, ignore_index=True)\n",
    "        df_tmp_collect = pd.concat([df_tmp_collect, df_tmp], ignore_index=True)\n",
    "\n",
    "        # Check if 2nd-step dataframe needs to be reset\n",
    "        if df_tmp_collect.shape[0] >= n_merge:\n",
    "            #df_CA_DA = df_CA_DA.append(df_tmp_collect, ignore_index=True)\n",
    "            df_CA_DA = pd.concat([df_CA_DA,df_tmp_collect], ignore_index=True)\n",
    "            df_tmp_collect = pd.DataFrame(columns=df_CA_DA.columns)\n",
    "\n",
    "        if not parse_limit is None:\n",
    "            parse_limit -= 1\n",
    "            if parse_limit<=0:\n",
    "                break\n",
    "    #df_CA_DA = df_CA_DA.append(df_tmp_collect, ignore_index=True)\n",
    "    df_CA_DA = pd.concat([df_CA_DA,df_tmp_collect], ignore_index=True)\n",
    "\n",
    "##### Timing Notes\n",
    "\n",
    "limit | n_merge | s/it | s total\n",
    "---|---|---|---\n",
    "500 | 1 | 0.13 | 1:06\n",
    "500 | 2 | 0.13 | 1:02\n",
    "500 | 10 | 0.12 | 1:01\n",
    "500 | 50 | 0.12 | 0:59.2\n",
    "500 | 237 | 0.11 | 0:57.5\n",
    "500 | 237 | 0.13 | 1:03\n",
    "1000 | 1 | 0.25 | 4:05\n",
    "1000 | 237 | 0.23 | 3:52 # maybe this was max instead of min?\n",
    "1000 | 1000 | 0.23 | 3:54\n",
    "1000 | 1000 | 0.24 | 3:55  # pd.concat instead of dataframe.append\n",
    "1000 | 237 | 0.22 | 3:38  # pd.concat instead of dataframe.append\n",
    "1000 | - | 0.27 | 4:25  # original, no 2-levels\n",
    "500  | - | 0.15 | 1:15  # original, no 2-levels\n",
    "500 | 237 | 0.07 | 0:34.3  # pd.concat instead of dataframe.append\n",
    "2000 | 237 | 0.07 | 2:13  # pd.concat instead of dataframe.append # Have not been resetting df_CA_DA!\n",
    "4000 | 237 | 0.06 | 4:15  # pd.concat instead of dataframe.append # Resetting df from here on, and concat too, and GetNextFeature instead of GetFeature(int) which may have been the bottleneck then...\n",
    "1000 | 237 | 0.06 | 1:01\n",
    "500 | 237 | 0.06 | 0:31.3\n",
    "1000 | 50 | 0.06 | 1:00\n",
    "1000 | 1 | 0.06 | 1:04\n",
    "1000 | 1 | 0.23 | 3:52  # Try once with GetFeature(i), yes, this was the culprit, it must parse anew each time.\n",
    "4000 | 1 | 0.09 | 5:41\n",
    "4000 | 5 | 0.06 | 4:11\n",
    "4000 | 20 | 0.06 | 3:41\n",
    "4000 | 50 | 0.06 | 3:54\n",
    "4000 | 50 | 0.06 | 3:57\n",
    "4000 | 100 | 0.06 | 3:58\n",
    "4000 | 175 | 0.06 | 4:03\n",
    "4000 | 237 | 0.06 | 4:08\n",
    "4000 | 500 | 0.06 | 4:18\n",
    "4000 | 500 | 0.06 | 3:50\n",
    "4000 | 1000 | 0.06 | 4:16\n",
    "4000 | 4000 | 0.07 | 4:58 # Oh, also hadn't reset the counter... adding that before last 500 and 30, that's been introducing variability too\n",
    "4000 | 1 | 0.06 | 4:16\n",
    "4000 | 30 | 0.06 | 4:17, 4:09 # Might change when tabs are changed (first with changing, second staying on same tab)\n",
    "4000 | 60 | 0.06 | 3:53, 4:03\n",
    "4000 | 200 | 0.06 | 3:56\n",
    "4000 | 500 | 0.06 | 3:44\n",
    "4000 | 1000 | 0.06 | 3:55\n",
    "4000 | 4000 | 0.06 | 4:03\n",
    "4000 | - | 0.06 | 4:04 # original, no 2-levels, with GetNextFeature\n",
    "\n",
    "Gain is marginal with the double layering... might be important for very large sets, but at 4000 features results in at most a 10% speedup.  Note that geopandas speedup is ~4,600%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3b537-558a-446b-9954-d4d1bf40ab84",
   "metadata": {},
   "source": [
    "#### Getting an appropriate EPSG projection\n",
    "\n",
    "Using UTM projections (of which there are 30, each subtending 6 degrees of longitude) was a commonly proposed method for projection for area calculation.  I went with the simpler EPSG-6931/2/3, which is easier due to one zone encompassing all of Canada (though with unknown accuracy tradeoff).  This approach is included just for reference.\n",
    "\n",
    "    srcSR = osr.SpatialReference()\n",
    "    srcSR.ImportFromEPSG(4326) # WGS84 Geographic\n",
    "    destSR   = osr.SpatialReference()\n",
    "\n",
    "    lyr.ResetReading()\n",
    "    for feat in lyr:\n",
    "        geom = feat.GetGeometryRef()\n",
    "        if not geom.IsEmpty():                 # make sure the geometry isn't empty\n",
    "            geom.AssignSpatialReference(srcSR) # you only need to do this if the shapefile isn't set or is set wrong\n",
    "            env = geom.GetEnvelope()           # get the Xmin, Ymin, Xmax, Ymax bounds\n",
    "            CentX = ( env[0] + env[2] ) / 2    # calculate the centre X of the whole geometry\n",
    "            Zone  = int((CentX + 180)/6) + 1   # see http://gis.stackexchange.com/questions/13291/computing-utm-zone-from-lat-long-point\n",
    "            EPSG  = 32600 + Zone               # get the EPSG code from the zone and the constant 32600 (all WGS84 UTM North start with 326)\n",
    "            destSR.ImportFromEPSG(EPSG)        # create the 'to' spatial reference\n",
    "            geom.TransformTo(destSR)           # project the geometry\n",
    "            print geom.GetArea()               # get the area in square metres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e3bdc-0b04-4c55-80b1-4d31fce5ed7c",
   "metadata": {},
   "source": [
    "#### Read in the Canadian data file: Original\n",
    "    gdf = geopandas.read_file('lda_000b16g_e.gml')\n",
    "    gdf.rename_geometry('Geometry', inplace=True) # Default geometry column name is 'geometry'; changed for consistent capitalization of columns\n",
    "    gdf.set_geometry('Geometry') # Renaming is insufficient; this sets special variable gdf.geometry = gdf['Geometry']\n",
    "    gdf['Area'] = gdf['Geometry'].to_crs(epsg=6931).area\n",
    "    gdf['Centroid'] = gdf['Geometry'].centroid\n",
    "    gdf['Geometry'] = gdf['Geometry'].to_crs(epsg=4326)\n",
    "    gdf['Centroid'] = gdf['Centroid'].to_crs(epsg=4326) # Only the set geometry is converted with gdf.to_crs(); all other geometry-containing columns must be converted explicitly; here we convert all columns explicitly\n",
    "    gdf['Centroid Latitude'] = gdf['Centroid'].geometry.y\n",
    "    gdf['Centroid Longitude'] = gdf['Centroid'].geometry.x\n",
    "    gdf.drop(columns = 'Centroid', inplace=True) # Because WKT Point cannot be serialized to JSON, we drop the Centroid column and keep only its float components\n",
    "    gdf_CA_DA = gdf # Rename because we may be generating additional variables\n",
    "    gdf_CA_DA.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad083b3-ea83-4d2c-8a7e-6a634af9116c",
   "metadata": {},
   "source": [
    "# Old Vancouver Extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06244a02-da6b-4031-89ac-a3b0d22d0471",
   "metadata": {},
   "source": [
    "Old Vancouver Extended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bec72-7ef2-49f3-ae9a-10003ca60bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityname = 'Vancouver'\n",
    "gdf_select = selectRegion(gdf_CA_DA, 'CDNAME', method='contains', names='Greater Vancouver')\n",
    "mp = folium.Map(location=getCityByName(cityname)['centroid'])\n",
    "mp.fit_bounds(getGDFBounds(gdf_select.to_crs(epsg=4326)))\n",
    "m = folium.GeoJson(\n",
    "            gdf_select.to_crs(epsg=4326).to_json(),\n",
    "            style_function=lambda feature: {\n",
    "                'fillColor': 'yellow',\n",
    "                'fillOpacity': 0.8,\n",
    "                'color':'black',\n",
    "                'weight': 1,\n",
    "                'opacity': 0.2,\n",
    "            },\n",
    "        ).add_to(mp)\n",
    "m.add_child(folium.features.GeoJsonTooltip(tooltip_DA))\n",
    "mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5755e-45ac-4602-bc4c-b5f499d99eac",
   "metadata": {},
   "source": [
    "# Unused Choropleth map development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192393ba-5931-476f-9819-6fc12eb588ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used - this naive choropleth displays only one map and doesn't allow much scale customization\n",
    "\n",
    "city_index = 1\n",
    "\n",
    "# create a plain world map\n",
    "city_map = folium.Map(location=cities[city_index]['centroid'], control_scale=True)\n",
    "city_map.fit_bounds(cities[city_index]['bounds'])\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=cities[city_index]['geojson'],\n",
    "    data=cities[city_index]['data'],\n",
    "    columns=['DAUID', 'Area'],\n",
    "    key_on='feature.properties.DAUID',\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.2,\n",
    "    legend_name='Area [square meters]'\n",
    ").add_to(city_map)\n",
    "\n",
    "# display map\n",
    "city_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbdf45-011c-4d60-9f22-543c1f528741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used - links choropleth to a layercontrol, but does not get the legend on the correct layer\n",
    "\n",
    "from branca.element import MacroElement\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "class BindColormap(MacroElement):\n",
    "    \"\"\"Binds a colormap to a given layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    colormap : branca.colormap.ColorMap\n",
    "        The colormap to bind.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer, colormap):\n",
    "        super(BindColormap, self).__init__()\n",
    "        self.layer = layer\n",
    "        self.colormap = colormap\n",
    "        self._template = Template(u\"\"\"\n",
    "        {% macro script(this, kwargs) %}\n",
    "            {{this.colormap.get_name()}}.svg[0][0].style.display = 'block';\n",
    "            {{this._parent.get_name()}}.on('overlayadd', function (eventLayer) {\n",
    "                if (eventLayer.layer == {{this.layer.get_name()}}) {\n",
    "                    {{this.colormap.get_name()}}.svg[0][0].style.display = 'block';\n",
    "                }});\n",
    "            {{this._parent.get_name()}}.on('overlayremove', function (eventLayer) {\n",
    "                if (eventLayer.layer == {{this.layer.get_name()}}) {\n",
    "                    {{this.colormap.get_name()}}.svg[0][0].style.display = 'none';\n",
    "                }});\n",
    "        {% endmacro %}\n",
    "        \"\"\")  # noqa\n",
    "        \n",
    "# https://gitter.im/python-visualization/folium?at=5a36090a03838b2f2a04649d\n",
    "print('Area Selection Criterion: CSDNAME contains the city name')\n",
    "import branca.element as bre\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "f = bre.Figure()\n",
    "sf = [[],[],[]]\n",
    "city_map = [[],[],[]]\n",
    "colormap = [[],[],[]]\n",
    "cp = [[],[],[]]\n",
    "for i, city in enumerate(cities):\n",
    "    sf[i] = f.add_subplot(1,len(cities),1+i)\n",
    "    city_map[i] = folium.Map(location=city['centroid'], control_scale=True)\n",
    "    sf[i].add_child(city_map[i])\n",
    "    \n",
    "    title_html = '''<h3 align=\"center\" style=\"font-size:16px;charset=utf-8\"><b>{}</b></h3>'''.format(city['name'])\n",
    "    city_map[i].get_root().html.add_child(folium.Element(title_html))\n",
    "    city_map[i].fit_bounds(city['bounds'])\n",
    "    cp[i] = folium.Choropleth(geo_data=city['geojson'],\n",
    "                                data=city['data'],\n",
    "                                columns=['DAUID', 'Area'],\n",
    "                                key_on='feature.properties.DAUID',\n",
    "                                fill_color='YlOrRd',\n",
    "                                fill_opacity=0.7, \n",
    "                                line_opacity=0.2\n",
    "                               )\n",
    "    city_map[i].add_child(cp[i])\n",
    "    city_map[i].add_child(folium.map.LayerControl())\n",
    "    city_map[i].add_child(BindColormap(cp[i],cp[i].color_scale))\n",
    "\n",
    "    city['map'] = city_map[i]\n",
    "\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bad1c4-edea-49d0-b8cf-51146ef9e920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "393b4286",
   "metadata": {},
   "source": [
    "# To get a list of functions in a module:\n",
    "from inspect import getmembers, isfunction\n",
    "\n",
    "from somemodule import foo\n",
    "print(getmembers(foo, isfunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postal Codes\n",
    "import requests\n",
    "# from bs4 import BeautifulSoup # had to install to environment in Anaconda\n",
    "import lxml # had to install to environment in Anaconda, backdated to 4.6.1 (4.6.2 current) for pandas read_html()\n",
    "import html5lib # had to install to environment in Anaconda (1.1 current) for pandas read_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of coordinate tuples of nonzero elements of matrix r\n",
    "list(zip(*np.nonzero(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9aefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577790d7",
   "metadata": {},
   "source": [
    "### Header that won't display on GitHub (tags not supported)\n",
    "\n",
    "    # <center>Applied Data Science Capstone</center>\n",
    "\n",
    "    #### <center>In completion of requirements for the IBM Data Science Professional Certificate on Coursera</center>\n",
    "\n",
    "    <center>Daniel Nezich</center>\n",
    "\n",
    "    <hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2c751",
   "metadata": {},
   "source": [
    "### Loading/Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19da48",
   "metadata": {},
   "source": [
    "#### Loading/Saving Without Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d59b2",
   "metadata": {},
   "source": [
    "Standalone\n",
    "\n",
    "    import dill\n",
    "    with open('GDF_FSA-DA-D.db','wb') as file:\n",
    "        dill.dump(gdf_union,file)\n",
    "    with open('GDF_FSA-DA-D_times.db','wb') as file:\n",
    "        dill.dump(times,file)\n",
    "    with open('GDF_FSA-DA-D_areas.db','wb') as file:\n",
    "        dill.dump(areas,file)\n",
    "\n",
    "    import dill\n",
    "    with open('GDF_FSA-DA-D.db','r') as file:\n",
    "        gdf_union = dill.load(file)\n",
    "    with open('GDF_FSA-DA-D_times.db','r') as file:\n",
    "        times = dill.load(file)\n",
    "    with open('GDF_FSA-DA-D_areas.db','r') as file:\n",
    "        areas = dill.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc2697",
   "metadata": {},
   "source": [
    "Option Block\n",
    "\n",
    "    try: # Results have been calculated previously, load them to save time\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D.db','rb') as file:\n",
    "            gdf_union = dill.load(file)\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_times.db','rb') as file:\n",
    "            times = dill.load(file)\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_areas.db','rb') as file:\n",
    "            areas = dill.load(file)\n",
    "        print('Results loaded from file')\n",
    "\n",
    "    except (FileNotFoundError, IOError):  # Results not found in file, regenerate them\n",
    "        gdf_union, times, areas = intersectGDF(gdf_CA_FSA_D,'CFSAUID',gdf_CA_DA_D,'DAUID',verbosity=1)\n",
    "\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D.db','wb+') as file:\n",
    "            dill.dump(gdf_union,file)\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_times.db','wb+') as file:\n",
    "            dill.dump(times,file)\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_areas.db','wb+') as file:\n",
    "            dill.dump(areas,file)\n",
    "        print('Results saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca7705",
   "metadata": {},
   "source": [
    "#### Loading/saving with compression\n",
    "\n",
    "Original load/compute/save logic for overlap computation:\n",
    "\n",
    "    try: # Results have been calculated previously, load them to save time\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_times.db.gz','rb') as file:\n",
    "            times = dill.loads(gzip.decompress(file.read()))\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_areas.db.gz','rb') as file:\n",
    "            areas = dill.loads(gzip.decompress(file.read()))\n",
    "        try: # If not available (e.g. on github, due to size), reconstruct the intersection gdf\n",
    "            with open(DIR_RESULTS+'GDF_FSA-DA_D.db.gz','rb') as file:\n",
    "                gdf_union = dill.loads(gzip.decompress(file.read()))\n",
    "        except (FileNotFoundError, IOError):\n",
    "            print('Recomputing gdf_union using areas loaded from file')\n",
    "            gdf_union_areas, times_areas, areas_areas= intersectGDFareas(gdf_CA_FSA_D,'CFSAUID',gdf_CA_DA_D,'DAUID',areas_in=areas,verbosity=1)\n",
    "            gdf_union = gdf_union_areas\n",
    "            with open(DIR_RESULTS+'GDF_FSA-DA_D.db.gz','wb+') as file:\n",
    "                file.write(gzip.compress(dill.dumps(gdf_union)))\n",
    "        print('Results loaded from file')\n",
    "\n",
    "    except (FileNotFoundError, IOError):  # Results not found in file, regenerate them\n",
    "        gdf_union, times, areas = intersectGDF(gdf_CA_FSA_D,'CFSAUID',gdf_CA_DA_D,'DAUID',verbosity=1)\n",
    "\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D.db.gz','wb+') as file:\n",
    "            file.write(gzip.compress(dill.dumps(gdf_union)))\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_times.db.gz','wb+') as file:\n",
    "            file.write(gzip.compress(dill.dumps(times)))\n",
    "        with open(DIR_RESULTS+'GDF_FSA-DA_D_areas.db.gz','wb+') as file:\n",
    "            file.write(gzip.compress(dill.dumps(areas)))\n",
    "        print('Results saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297f0b6",
   "metadata": {},
   "source": [
    "## ExtendBounds Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62f606",
   "metadata": {},
   "source": [
    "### Original extendBounds Function and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0df3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extendBounds(bounds,method='nearestLeadingDigit',scale=10):\n",
    "    '''Extend bounds (low, high) to give round numbers for scalebars\n",
    "\n",
    "    The low bound is decreased and the high bound is increased according to\n",
    "        method to the first number satisfying the method conditions.\n",
    "    Returns a new bound which includes the old bounds in its entirety\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bounds: (low_bound, high_bound) list or tuple\n",
    "    method: str describing the extension method\n",
    "        'nearestLeadingDigit': Bounds are nearest numbers with leading digit followed by zeros\n",
    "        'nearestPower': Bounds are nearest powers of scale (scale must be > 1).  For negative numbers, the sign and direction are reversed, the extension performed, then the sign of the result is reversed back.\n",
    "        'nearestMultiple': Bounds are nearest multiple of scale (scale must be > 0)\n",
    "        'round': Bounds are rounded\n",
    "    scale: numeric as described in method options\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    2-element tuple of extended bounds e.g. (newlow,newhigh)\n",
    "    '''\n",
    "    if bounds[0]>bounds[1]:\n",
    "        print('bounds must be ordered from least to greatest')\n",
    "        return None    \n",
    "    if method=='nearestLeadingDigit':\n",
    "        iszero = np.array(bounds)==0\n",
    "        isnegative = np.array(bounds) < 0\n",
    "        offsets = [1 if isnegative[0] else 0, 0 if isnegative[1] else 1]\n",
    "        power = [0 if z else np.floor(np.log10(abs(b))) for b, z in zip(bounds, iszero)]\n",
    "        firstdigit = [abs(b)//np.power(10,p) for b, p in zip(bounds, power)]\n",
    "        exceeds = [abs(b)>f*np.power(10,p) for b, f, p in zip(bounds, firstdigit, power)]\n",
    "        newbounds = [abs(b) if not t else (f+o)*np.power(10,p) for b, t, n, f, o, p in zip(bounds, exceeds, isnegative, firstdigit, offsets, power)]\n",
    "        newbounds = [-n if t else n for n, t in zip(newbounds,isnegative)]\n",
    "    elif method=='nearestPower':\n",
    "        try:\n",
    "            scale = float(scale)\n",
    "            if scale<=1:\n",
    "                print('scale should be greater than 1')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number greater than 1')\n",
    "            return None\n",
    "        isnegative = np.array(bounds) < 0\n",
    "        roundfuns = [np.ceil if isnegative[0] else np.floor, np.floor if isnegative[1] else np.ceil]\n",
    "        newbounds = [0 if b==0 else np.power(scale, r(np.log10(abs(b))/np.log10(scale))) for b, r in zip(bounds,roundfuns)]\n",
    "        newbounds = [-n if t else n for n, t in zip(newbounds,isnegative)]\n",
    "    elif method=='nearestMultiple':\n",
    "        try:\n",
    "            scale = float(scale)\n",
    "            if scale<=0:\n",
    "                print('scale should be greater than 0')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number greater than 0')\n",
    "            return None\n",
    "        newbounds = [scale*(np.floor(bounds[0]/scale)), scale*(np.ceil(bounds[1]/scale))]\n",
    "    elif method=='round':\n",
    "        newbounds = [np.floor(bounds[0]), np.ceil(bounds[1])]\n",
    "    else:\n",
    "        print('Invalid method, see help(extendBounds)')\n",
    "        return None\n",
    "    return newbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a005e3",
   "metadata": {},
   "source": [
    "    print(\"Testing invalid method\")\n",
    "    print(\"  Expect errors:\")\n",
    "    print(f\"{extendBounds([11,130],'invalid')}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Testing method 'nearestLeadingDigit'\")\n",
    "    print(\"  Expect errors:\")\n",
    "    print(f\"{extendBounds([9,-930],'nearestLeadingDigit')}\")\n",
    "    print(f\"{extendBounds([-9,-930],'nearestLeadingDigit')}\")\n",
    "    print(\"  Expect success:\")\n",
    "    print(f\"{extendBounds([11,130],'nearestLeadingDigit')}\",)\n",
    "    print(f\"{extendBounds([11,130],'nearestLeadingDigit',-1)}\")\n",
    "    print(f\"{extendBounds([9,930],'nearestLeadingDigit')}\")\n",
    "    print(f\"{extendBounds([-9,930],'nearestLeadingDigit')}\")\n",
    "    print(f\"{extendBounds([-990,-930],'nearestLeadingDigit')}\")\n",
    "    print(f\"{extendBounds([-990,0.05],'nearestLeadingDigit')}\")\n",
    "    print(f\"{extendBounds([0,0.052],'nearestLeadingDigit')}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Testing method 'nearestPower'\")\n",
    "    print(\"  Expect errors:\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',-2)}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',0)}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',1)}\")\n",
    "    print(f\"{extendBounds([-11,-130],'nearestPower',10)}\")\n",
    "    print(\"  Expect success:\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower')}\")\n",
    "    print(f\"{extendBounds([10,100],'nearestPower')}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',1.1)}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',2)}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',10)}\")\n",
    "    print(f\"{extendBounds([11,130],'nearestPower',10.)}\")\n",
    "    print(f\"{extendBounds([-11,130],'nearestPower',10)}\")\n",
    "    print(f\"{extendBounds([-5100,-130],'nearestPower',10)}\")\n",
    "    print(f\"{extendBounds([-.0101,-0.00042],'nearestPower',10)}\")\n",
    "    print(f\"{extendBounds([0,0.00042],'nearestPower',10)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Testing method 'nearestMultiple'\")\n",
    "    print(\"  Expect errors:\")\n",
    "    print(f\"{extendBounds([11,132],'nearestMultiple',-2)}\")\n",
    "    print(f\"{extendBounds([11,132],'nearestMultiple',0)}\")\n",
    "    print(f\"{extendBounds([0,-10],'nearestMultiple',100)}\")\n",
    "    print(\"  Expect success:\")\n",
    "    print(f\"{extendBounds([11,132],'nearestMultiple')}\")\n",
    "    print(f\"{extendBounds([10,130],'nearestMultiple')}\")\n",
    "    print(f\"{extendBounds([11.55,132.55],'nearestMultiple',0.1)}\")\n",
    "    print(f\"{extendBounds([11.55,132.55],'nearestMultiple',1)}\")\n",
    "    print(f\"{extendBounds([11.55,132.55],'nearestMultiple',100)}\")\n",
    "    print(f\"{extendBounds([-11,132],'nearestMultiple',10)}\")\n",
    "    print(f\"{extendBounds([-1121,-132],'nearestMultiple',10)}\")\n",
    "    print(f\"{extendBounds([-10,-10],'nearestMultiple',10)}\")\n",
    "    print(f\"{extendBounds([-10,-10],'nearestMultiple',100)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Testing method 'round'\")\n",
    "    print(\"  Expect errors:\")\n",
    "    print(f\"{extendBounds([-11.1,-132.1],'round')}\")\n",
    "    print(\"  Expect success:\")\n",
    "    print(f\"{extendBounds([11.1,132.1],'round')}\")\n",
    "    print(f\"{extendBounds([10,130],'round')}\")\n",
    "    print(f\"{extendBounds([11.1,132.1],'round',-2)}\")\n",
    "    print(f\"{extendBounds([-11.1,132.1],'round')}\")\n",
    "    print(f\"{extendBounds([-1100.1,-132.1],'round')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ad1de",
   "metadata": {},
   "source": [
    "    Testing invalid method\n",
    "      Expect errors:\n",
    "    Invalid method, see help(extendBounds)\n",
    "    None\n",
    "\n",
    "    Testing method 'nearestLeadingDigit'\n",
    "      Expect errors:\n",
    "    bounds must be ordered from least to greatest\n",
    "    None\n",
    "    bounds must be ordered from least to greatest\n",
    "    None\n",
    "      Expect success:\n",
    "    [10.0, 200.0]\n",
    "    [10.0, 200.0]\n",
    "    [9, 1000.0]\n",
    "    [-9, 1000.0]\n",
    "    [-1000.0, -900.0]\n",
    "    [-1000.0, 0.05]\n",
    "    [0, 0.06]\n",
    "\n",
    "    Testing method 'nearestPower'\n",
    "      Expect errors:\n",
    "    scale should be greater than 1\n",
    "    None\n",
    "    scale should be greater than 1\n",
    "    None\n",
    "    scale should be greater than 1\n",
    "    None\n",
    "    bounds must be ordered from least to greatest\n",
    "    None\n",
    "      Expect success:\n",
    "    [10.0, 1000.0]\n",
    "    [10.0, 100.0]\n",
    "    [10.834705943388395, 142.04293198443193]\n",
    "    [8.0, 256.0]\n",
    "    [10.0, 1000.0]\n",
    "    [10.0, 1000.0]\n",
    "    [-100.0, 1000.0]\n",
    "    [-10000.0, -100.0]\n",
    "    [-0.1, -0.0001]\n",
    "    [0, 0.001]\n",
    "\n",
    "    Testing method 'nearestMultiple'\n",
    "      Expect errors:\n",
    "    scale should be greater than 0\n",
    "    None\n",
    "    scale should be greater than 0\n",
    "    None\n",
    "    bounds must be ordered from least to greatest\n",
    "    None\n",
    "      Expect success:\n",
    "    [10.0, 140.0]\n",
    "    [10.0, 130.0]\n",
    "    [11.5, 132.6]\n",
    "    [11.0, 133.0]\n",
    "    [0.0, 200.0]\n",
    "    [-20.0, 140.0]\n",
    "    [-1130.0, -130.0]\n",
    "    [-10.0, -10.0]\n",
    "    [-100.0, -0.0]\n",
    "\n",
    "    Testing method 'round'\n",
    "      Expect errors:\n",
    "    bounds must be ordered from least to greatest\n",
    "    None\n",
    "      Expect success:\n",
    "    [11.0, 133.0]\n",
    "    [10.0, 130.0]\n",
    "    [11.0, 133.0]\n",
    "    [-12.0, 133.0]\n",
    "    [-1101.0, -132.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914d6ad",
   "metadata": {},
   "source": [
    "### New extendBounds Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4620143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extendBound(bound,direction='up',method='nearestLeadingDigit',scale=10):\n",
    "    '''Extend bound to next 'round' number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bound: float or float castable number or a list thereof\n",
    "    direction: {'up','down',nonzero number} or a list of these values indicating the direction to round in\n",
    "    method: str describing the extension method\n",
    "        'nearestLeadingDigit': Bound is nearest numbers with leading digit followed by zeros\n",
    "        'nearestPower': Bound is nearest integer power of scale (scale must be > 1).  For negative numbers, the sign and direction are reversed, the extension performed, then the sign of the result is reversed back.\n",
    "        'nearestMultiple': Bound is nearest multiple of scale (scale must be > 0)\n",
    "        'round': Bound is rounded using the default method\n",
    "    scale: numeric as described in method options or a list thereof\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float: the extended bound\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    All inputs, if not single-valued, must be lists of length equal to input bound\n",
    "    TODO: extend so that method may also be a list\n",
    "    TODO: replace prints with raising errors\n",
    "    '''\n",
    "    import numpy as np\n",
    "    \n",
    "    # Check and adjust the length of inputs\n",
    "    unlist_bound = False\n",
    "    if not(type(bound) in {list,tuple,range}):\n",
    "        bound = [bound]\n",
    "        unlist_bound = True\n",
    "    acceptable_len = set((1,len(bound)))\n",
    "    if not(type(direction) in {list,tuple,range}):\n",
    "        direction = [direction]\n",
    "    if not(len(direction) in acceptable_len):\n",
    "        print('\"direction\" must have length 1 or length equal to the length of \"bound\"')\n",
    "        return None\n",
    "    if (type(method) in {str}):\n",
    "        method = [method]\n",
    "    if not(len(method) in acceptable_len):\n",
    "        print('\"method\" must have length 1 or length equal to the length of \"bound\"')\n",
    "        return None\n",
    "    if not(type(scale) in {list,tuple,range}):\n",
    "        scale = [scale]\n",
    "    if not(len(scale) in acceptable_len):\n",
    "        print('\"scale\" must have length 1 or length equal to the length of \"bound\"')\n",
    "        return None\n",
    "    if len(bound)>1:\n",
    "        if len(direction)==1: direction = [direction[0] for b in bound]\n",
    "        if len(scale)==1: scale = [scale[0] for b in bound]\n",
    "        \n",
    "    # If multiple methods are specified, recursively call this function for each method and reassemble results\n",
    "    if len(bound)>1 and len(method)>1:\n",
    "        ret = np.array([None for b in bound])\n",
    "        for m in list(set(method)):\n",
    "            ind = np.where(np.array(method)==m)\n",
    "            ret[ind] = extendBound(list(np.array(bound)[ind]),list(np.array(direction)[ind]),m,list(np.array(scale)[ind]))\n",
    "        return list(ret)\n",
    "    \n",
    "    # Convert direction to a logical array roundup\n",
    "    try:\n",
    "        roundup = [True if d=='up' else False if d=='down' else True if float(d)>0 else False if float(d)<0 else None for d in direction]\n",
    "    except:\n",
    "        print('direction must be \"up\", \"down\", or a non-negative number')\n",
    "        return None\n",
    "    if any([r==None for r in roundup]):\n",
    "        print('direction must be \"up\", \"down\", or a non-negative number')\n",
    "        return None\n",
    "    \n",
    "    # Cases for multiple methods handled above, return to string method\n",
    "    method = method[0]\n",
    "    \n",
    "    # Execute the conversions\n",
    "    if method=='nearestLeadingDigit':\n",
    "        iszero = np.array(bound)==0\n",
    "        isnegative = np.array(bound) < 0\n",
    "        offsets = np.logical_xor(roundup, isnegative)\n",
    "        power = [0 if z else np.floor(np.log10(abs(b))) for b, z in zip(bound, iszero)]\n",
    "        firstdigit = [abs(b)//np.power(10,p) for b, p in zip(bound, power)]\n",
    "        exceeds = [abs(b)>f*np.power(10,p) for b, f, p in zip(bound, firstdigit, power)]\n",
    "        newbound = [abs(b) if not t else (f+o)*np.power(10,p) for b, t, n, f, o, p in zip(bound, exceeds, isnegative, firstdigit, offsets, power)]\n",
    "        newbound = [-n if t else n for n, t in zip(newbound,isnegative)]\n",
    "    elif method=='nearestPower':\n",
    "        try:\n",
    "            scale = [float(s) for s in scale]\n",
    "            if any([s<=1 for s in scale]):\n",
    "                print('scale should be greater than 1')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number or list of numbers greater than 1')\n",
    "            return None\n",
    "        isnegative = np.array(bound) < 0\n",
    "        offsets = np.logical_xor(roundup, isnegative)\n",
    "        roundfuns = [np.ceil if o else np.floor for o in offsets]\n",
    "        newbound = [0 if b==0 else np.power(s, r(np.log10(abs(b))/np.log10(s))) for b, r, s in zip(bound,roundfuns,scale)]\n",
    "        newbound = [-n if t else n for n, t in zip(newbound,isnegative)]\n",
    "    elif method=='nearestMultiple':\n",
    "        try:\n",
    "            scale = [float(s) for s in scale]\n",
    "            if any([s<=0 for s in scale]):\n",
    "                print('scale should be greater than 0')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number or list of numbers greater than 0')\n",
    "            return None\n",
    "        roundfuns = [np.ceil if r else np.floor for r in roundup]\n",
    "        newbound = [s*(r(b/s)) for b, r, s in zip(bound,roundfuns,scale)]\n",
    "    elif method=='round':\n",
    "        roundfuns = [np.ceil if r else np.floor for r in roundup]\n",
    "        newbound = [f(b) for b, f in zip(bound, roundfuns)]\n",
    "    else:\n",
    "        print('Invalid method, see help(extendBound)')\n",
    "        return None\n",
    "    return newbound[0] if unlist_bound else newbound\n",
    "\n",
    "def extendBounds(bounds,method='nearestLeadingDigit',scale=10):\n",
    "    if bounds[0]>bounds[1]:\n",
    "        print('bounds must be ordered from least to greatest')\n",
    "        return None    \n",
    "    return extendBound(bounds,direction=['down','up'],method=method,scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a310b",
   "metadata": {},
   "source": [
    "### Newest extendBounds and testing: list-castable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca5a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extendBound(bound,direction='up',method='nearestLeadingDigit',scale=10):\n",
    "    '''Extend bound to next 'round' number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bound: float or float castable number or a list thereof\n",
    "    direction: {'up','down',nonzero number} or a list of these values indicating the direction to round in\n",
    "    method: str describing the extension method\n",
    "        'nearestLeadingDigit': Bound is nearest numbers with leading digit followed by zeros\n",
    "        'nearestPower': Bound is nearest integer power of scale (scale must be > 1).  For negative numbers, the sign and direction are reversed, the extension performed, then the sign of the result is reversed back.\n",
    "        'nearestMultiple': Bound is nearest multiple of scale (scale must be > 0)\n",
    "        'round': Bound is rounded using the default method\n",
    "    scale: numeric as described in method options or a list thereof\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float: the extended bound\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    All inputs, if not single-valued, must be list-castable and of equal length\n",
    "    If all inputs are single-valued, the output is a float, otherwise it is a list of floats\n",
    "    '''\n",
    "    import numpy as np\n",
    "    \n",
    "    # Check and adjust the length of inputs\n",
    "    unlist = False\n",
    "    try:\n",
    "        bound = list(bound)\n",
    "    except:\n",
    "        try:\n",
    "            bound = [bound]\n",
    "            unlist = True\n",
    "        except:\n",
    "            print(\"Input 'bound' must be numeric or convertible to list type.\")\n",
    "            return None\n",
    "    try:\n",
    "        if type(direction)==str:\n",
    "            direction = [direction]\n",
    "        direction = list(direction)\n",
    "    except:\n",
    "        try:\n",
    "            direction = [direction]\n",
    "        except:\n",
    "            print(\"Input 'direction' must be a string or nonzero number or convertible to list type.\")\n",
    "            return None\n",
    "    try:\n",
    "        if type(method)==str:\n",
    "            method = [method]\n",
    "        method = list(method)\n",
    "    except:\n",
    "        try:\n",
    "            method = [method]\n",
    "        except:\n",
    "            print(\"Input 'method' must be a string or convertible to list type.\")\n",
    "            return None\n",
    "    try:\n",
    "        scale = list(scale)\n",
    "    except:\n",
    "        try:\n",
    "            scale = [scale]\n",
    "        except:\n",
    "            print(\"Input 'scale' must be numeric or convertible to list type.\")\n",
    "            return None\n",
    "    inputs = [bound, direction, method, scale]\n",
    "    lengths = [len(i) for i in inputs]\n",
    "    set_lengths = set(lengths)\n",
    "    max_len = max(set_lengths)\n",
    "    set_lengths.remove(1)\n",
    "    if len(set_lengths)>1:\n",
    "        print('Inputs must be of the same length or of length one.  See help(extendBound)')\n",
    "        return None\n",
    "    if max_len>1: # can this be converted to a looped statement?\n",
    "        if len(bound)==1:\n",
    "            bound = bound*max_len\n",
    "        if len(direction)==1:\n",
    "            direction = direction*max_len\n",
    "        if len(method)==1:\n",
    "            method = method*max_len\n",
    "        if len(scale)==1:\n",
    "            scale = scale*max_len\n",
    "        unlist = False\n",
    "\n",
    "    # If multiple methods are specified, recursively call this function for each method and reassemble results\n",
    "    if len(bound)>1 and len(set(method))>1:\n",
    "        ret = np.array([None for b in bound])\n",
    "        for m in list(set(method)):\n",
    "            ind = np.where(np.array(method)==m)\n",
    "            ret[ind] = extendBound(list(np.array(bound)[ind]),list(np.array(direction)[ind]),m,list(np.array(scale)[ind]))\n",
    "        return list(ret)\n",
    "    \n",
    "    # Convert direction to a logical array roundup\n",
    "    try:\n",
    "        roundup = [True if d=='up' else False if d=='down' else True if float(d)>0 else False if float(d)<0 else None for d in direction]\n",
    "    except:\n",
    "        print('direction must be \"up\", \"down\", or a non-negative number')\n",
    "        return None\n",
    "    if any([r==None for r in roundup]):\n",
    "        print('direction must be \"up\", \"down\", or a non-negative number')\n",
    "        return None\n",
    "    \n",
    "    # Cases for multiple methods handled above, return to string method\n",
    "    method = method[0]\n",
    "    \n",
    "    # Execute the conversions\n",
    "    if method=='nearestLeadingDigit':\n",
    "        iszero = np.array(bound)==0\n",
    "        isnegative = np.array(bound) < 0\n",
    "        offsets = np.logical_xor(roundup, isnegative)\n",
    "        power = [0 if z else np.floor(np.log10(abs(b))) for b, z in zip(bound, iszero)]\n",
    "        firstdigit = [abs(b)//np.power(10,p) for b, p in zip(bound, power)]\n",
    "        exceeds = [abs(b)>f*np.power(10,p) for b, f, p in zip(bound, firstdigit, power)]\n",
    "        newbound = [abs(b) if not t else (f+o)*np.power(10,p) for b, t, n, f, o, p in zip(bound, exceeds, isnegative, firstdigit, offsets, power)]\n",
    "        newbound = [-n if t else n for n, t in zip(newbound,isnegative)]\n",
    "    elif method=='nearestPower':\n",
    "        try:\n",
    "            scale = [float(s) for s in scale]\n",
    "            if any([s<=1 for s in scale]):\n",
    "                print('scale should be greater than 1')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number or list of numbers greater than 1')\n",
    "            return None\n",
    "        isnegative = np.array(bound) < 0\n",
    "        offsets = np.logical_xor(roundup, isnegative)\n",
    "        roundfuns = [np.ceil if o else np.floor for o in offsets]\n",
    "        newbound = [0 if b==0 else np.power(s, r(np.log10(abs(b))/np.log10(s))) for b, r, s in zip(bound,roundfuns,scale)]\n",
    "        newbound = [-n if t else n for n, t in zip(newbound,isnegative)]\n",
    "    elif method=='nearestMultiple':\n",
    "        try:\n",
    "            scale = [float(s) for s in scale]\n",
    "            if any([s<=0 for s in scale]):\n",
    "                print('scale should be greater than 0')\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print('scale should be a number or list of numbers greater than 0')\n",
    "            return None\n",
    "        roundfuns = [np.ceil if r else np.floor for r in roundup]\n",
    "        newbound = [s*(r(b/s)) for b, r, s in zip(bound,roundfuns,scale)]\n",
    "    elif method=='round':\n",
    "        roundfuns = [np.ceil if r else np.floor for r in roundup]\n",
    "        newbound = [f(b) for b, f in zip(bound, roundfuns)]\n",
    "    else:\n",
    "        print('Invalid method, see help(extendBound)')\n",
    "        return None\n",
    "    return newbound[0] if unlist else newbound\n",
    "\n",
    "def extendBounds(bounds,method='nearestLeadingDigit',scale=10):\n",
    "    if bounds[0]>bounds[1]:\n",
    "        print('bounds must be ordered from least to greatest')\n",
    "        return None    \n",
    "    return extendBound(bounds,direction=['down','up'],method=method,scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a06125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing function extendBounds\n",
      "\n",
      "Testing invalid method\n",
      "  Expect errors:\n",
      "Invalid method, see help(extendBound)\n",
      "Input: [11, 130] invalid 10   Output: None   Expected: None   Passed: True\n",
      "\n",
      "Testing method 'nearestLeadingDigit'\n",
      "  Expect errors:\n",
      "bounds must be ordered from least to greatest\n",
      "Input: [9, -930] nearestLeadingDigit 10   Output: None   Expected: None   Passed: True\n",
      "bounds must be ordered from least to greatest\n",
      "Input: [-9, -930] nearestLeadingDigit 10   Output: None   Expected: None   Passed: True\n",
      "  Expect success:\n",
      "Input: [11, 130] nearestLeadingDigit 10   Output: [10.0, 200.0]   Expected: [10, 200]   Passed: True\n",
      "Input: [11, 130] nearestLeadingDigit -1   Output: [10.0, 200.0]   Expected: [10, 200]   Passed: True\n",
      "Input: [9, 930] nearestLeadingDigit 10   Output: [9, 1000.0]   Expected: [9, 1000]   Passed: True\n",
      "Input: [-9, 930] nearestLeadingDigit 10   Output: [-9, 1000.0]   Expected: [-9, 1000]   Passed: True\n",
      "Input: [-990, -930] nearestLeadingDigit 10   Output: [-1000.0, -900.0]   Expected: [-1000, -900]   Passed: True\n",
      "Input: [-990, 0.05] nearestLeadingDigit 10   Output: [-1000.0, 0.05]   Expected: [-1000, 0.05]   Passed: True\n",
      "Input: [0, 0.052] nearestLeadingDigit 10   Output: [0, 0.06]   Expected: [0, 0.06]   Passed: True\n",
      "\n",
      "Testing method 'nearestPower'\n",
      "  Expect errors:\n",
      "scale should be greater than 1\n",
      "Input: [11, 130] nearestPower -2   Output: None   Expected: None   Passed: True\n",
      "scale should be greater than 1\n",
      "Input: [11, 130] nearestPower 0   Output: None   Expected: None   Passed: True\n",
      "scale should be greater than 1\n",
      "Input: [11, 130] nearestPower 1   Output: None   Expected: None   Passed: True\n",
      "bounds must be ordered from least to greatest\n",
      "Input: [-11, -130] nearestPower 10   Output: None   Expected: None   Passed: True\n",
      "  Expect success:\n",
      "Input: [11, 130] nearestPower 10   Output: [10.0, 1000.0]   Expected: [10, 1000]   Passed: True\n",
      "Input: [10, 100] nearestPower 10   Output: [10.0, 100.0]   Expected: [10, 100]   Passed: True\n",
      "Input: [11, 130] nearestPower 1.1   Output: [10.834705943388395, 142.04293198443193]   Expected: [10.834705943388395, 142.04293198443193]   Passed: True\n",
      "Input: [11, 130] nearestPower 2   Output: [8.0, 256.0]   Expected: [8, 256]   Passed: True\n",
      "Input: [11, 130] nearestPower 10   Output: [10.0, 1000.0]   Expected: [10, 1000]   Passed: True\n",
      "Input: [11, 130] nearestPower 10.0   Output: [10.0, 1000.0]   Expected: [10, 1000]   Passed: True\n",
      "Input: [-11, 130] nearestPower 10   Output: [-100.0, 1000.0]   Expected: [-100, 1000]   Passed: True\n",
      "Input: [-5100, -130] nearestPower 10   Output: [-10000.0, -100.0]   Expected: [-10000, -100]   Passed: True\n",
      "Input: [-0.0101, -0.00042] nearestPower 10   Output: [-0.1, -0.0001]   Expected: [-0.1, -0.0001]   Passed: True\n",
      "Input: [0, 0.00042] nearestPower 10   Output: [0, 0.001]   Expected: [0, 0.001]   Passed: True\n",
      "\n",
      "Testing method 'nearestMultiple'\n",
      "  Expect errors:\n",
      "scale should be greater than 0\n",
      "Input: [11, 132] nearestMultiple -2   Output: None   Expected: None   Passed: True\n",
      "scale should be greater than 0\n",
      "Input: [11, 132] nearestMultiple 0   Output: None   Expected: None   Passed: True\n",
      "bounds must be ordered from least to greatest\n",
      "Input: [0, -10] nearestMultiple 100   Output: None   Expected: None   Passed: True\n",
      "  Expect success:\n",
      "Input: [11, 132] nearestMultiple 10   Output: [10.0, 140.0]   Expected: [10, 140]   Passed: True\n",
      "Input: [10, 130] nearestMultiple 10   Output: [10.0, 130.0]   Expected: [10, 130]   Passed: True\n",
      "Input: [11.55, 132.55] nearestMultiple 0.1   Output: [11.5, 132.6]   Expected: [11.5, 132.6]   Passed: True\n",
      "Input: [11.55, 132.55] nearestMultiple 1   Output: [11.0, 133.0]   Expected: [11, 133]   Passed: True\n",
      "Input: [11.55, 132.55] nearestMultiple 100   Output: [0.0, 200.0]   Expected: [0, 200]   Passed: True\n",
      "Input: [-11, 132] nearestMultiple 10   Output: [-20.0, 140.0]   Expected: [-20, 140]   Passed: True\n",
      "Input: [-1121, -132] nearestMultiple 10   Output: [-1130.0, -130.0]   Expected: [-1130, -130]   Passed: True\n",
      "Input: [-10, -10] nearestMultiple 10   Output: [-10.0, -10.0]   Expected: [-10, -10]   Passed: True\n",
      "Input: [-10, -10] nearestMultiple 100   Output: [-100.0, -0.0]   Expected: [-100, 0]   Passed: True\n",
      "\n",
      "Testing method 'round'\n",
      "  Expect errors:\n",
      "bounds must be ordered from least to greatest\n",
      "Input: [-11.1, -132.1] round 10   Output: None   Expected: None   Passed: True\n",
      "  Expect success:\n",
      "Input: [11.1, 132.1] round 10   Output: [11.0, 133.0]   Expected: [11, 133]   Passed: True\n",
      "Input: [10, 130] round 10   Output: [10.0, 130.0]   Expected: [10, 130]   Passed: True\n",
      "Input: [11.1, 132.1] round -2   Output: [11.0, 133.0]   Expected: [11, 133]   Passed: True\n",
      "Input: [-11.1, 132.1] round 10   Output: [-12.0, 133.0]   Expected: [-12, 133]   Passed: True\n",
      "Input: [-1100.1, -132.1] round 10   Output: [-1101.0, -132.0]   Expected: [-1101, -132]   Passed: True\n",
      "\n",
      "Testing array execution\n",
      "  Expect errors:\n",
      "  Expect success:\n",
      "    method\n",
      "Input: 1.5 up nearestLeadingDigit 4   Output: 2.0   Expected: 2   Passed: True\n",
      "Input: 1.5 up nearestPower 4   Output: 4.0   Expected: 4   Passed: True\n",
      "Input: 1.5 up nearestMultiple 4   Output: 4.0   Expected: 4   Passed: True\n",
      "Input: 1.5 up round 4   Output: 2.0   Expected: 2   Passed: True\n",
      "    direction\n",
      "Input: 1.5 up nearestMultiple 4   Output: 4.0   Expected: 4   Passed: True\n",
      "Input: 1.5 0.1 nearestMultiple 4   Output: 4.0   Expected: 4   Passed: True\n",
      "Input: 1.5 down nearestMultiple 4   Output: 0.0   Expected: 0   Passed: True\n",
      "Input: 1.5 -0.1 nearestMultiple 4   Output: 0.0   Expected: 0   Passed: True\n",
      "    broadcasting\n",
      "Input: [1.5] up nearestMultiple 1   Output: [2.0]   Expected: [2]   Passed: True\n",
      "Input: [1.5, 2.5] up nearestMultiple 1   Output: [2.0, 3.0]   Expected: [2, 3]   Passed: True\n",
      "Input: 1.5 ['up', 'down'] nearestMultiple 1   Output: [2.0, 1.0]   Expected: [2, 1]   Passed: True\n",
      "Input: 1.5 up ['nearestLeadingDigit', 'nearestPower', 'nearestMultiple', 'round'] 3   Output: [2.0, 3.0, 3.0, 2.0]   Expected: [2, 3, 3, 2]   Passed: True\n",
      "Input: 1.5 up nearestMultiple [1, 5, 10]   Output: [2.0, 5.0, 10.0]   Expected: [2, 5, 10]   Passed: True\n",
      "\n",
      "All tests passed: True\n"
     ]
    }
   ],
   "source": [
    "# Unit test of extendBounds\n",
    "#   TODO: check out the builtin unittest module and convert this code to use that testing structure\n",
    "\n",
    "# Get default arguments from https://stackoverflow.com/questions/12627118/get-a-function-arguments-default-value\n",
    "import inspect\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }\n",
    "\n",
    "defaults = get_default_args(extendBound)\n",
    "def test_extendBound(bounds,direction=defaults['direction'],method=defaults['method'],scale=defaults['scale'],expected=None): # default arguments taken from extendBound; not sure how to get defaults when not supplied\n",
    "    output = extendBound(bounds,direction,method,scale)\n",
    "    print('Input:',bounds,direction,method,scale,'  Output:',output,'  Expected:',expected,'  Passed:',output==expected)\n",
    "    return output==expected\n",
    "\n",
    "defaults = get_default_args(extendBounds)\n",
    "def test_extendBounds(bounds,method=defaults['method'],scale=defaults['scale'],expected=None): # default arguments taken from extendBounds; not sure how to get defaults when not supplied\n",
    "    output = extendBounds(bounds,method,scale)\n",
    "    print('Input:',bounds,method,scale,'  Output:',output,'  Expected:',expected,'  Passed:',output==expected)\n",
    "    return output==expected\n",
    "\n",
    "print('Testing function extendBounds\\n')\n",
    "\n",
    "passed = True\n",
    "print(\"Testing invalid method\")\n",
    "print(\"  Expect errors:\")\n",
    "passed = test_extendBounds([11,130],'invalid',expected=None) and passed\n",
    "print()\n",
    "\n",
    "print(\"Testing method 'nearestLeadingDigit'\")\n",
    "print(\"  Expect errors:\")\n",
    "passed = test_extendBounds([9,-930],'nearestLeadingDigit',expected=None) and passed\n",
    "passed = test_extendBounds([-9,-930],'nearestLeadingDigit',expected=None) and passed\n",
    "print(\"  Expect success:\")\n",
    "passed = test_extendBounds([11,130],'nearestLeadingDigit',expected=[10,200]) and passed\n",
    "passed = test_extendBounds([11,130],'nearestLeadingDigit',-1,expected=[10,200]) and passed\n",
    "passed = test_extendBounds([9,930],'nearestLeadingDigit',expected=[9,1000]) and passed\n",
    "passed = test_extendBounds([-9,930],'nearestLeadingDigit',expected=[-9,1000]) and passed\n",
    "passed = test_extendBounds([-990,-930],'nearestLeadingDigit',expected=[-1000,-900]) and passed\n",
    "passed = test_extendBounds([-990,0.05],'nearestLeadingDigit',expected=[-1000,0.05]) and passed\n",
    "passed = test_extendBounds([0,0.052],'nearestLeadingDigit',expected=[0,0.06]) and passed\n",
    "print()\n",
    "\n",
    "print(\"Testing method 'nearestPower'\")\n",
    "print(\"  Expect errors:\")\n",
    "passed = test_extendBounds([11,130],'nearestPower',-2,expected=None) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',0,expected=None) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',1,expected=None) and passed\n",
    "passed = test_extendBounds([-11,-130],'nearestPower',10,expected=None) and passed\n",
    "print(\"  Expect success:\")\n",
    "passed = test_extendBounds([11,130],'nearestPower',expected=[10,1000]) and passed\n",
    "passed = test_extendBounds([10,100],'nearestPower',expected=[10,100]) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',1.1,expected=[10.834705943388395, 142.04293198443193]) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',2,expected=[8,256]) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',10,expected=[10,1000]) and passed\n",
    "passed = test_extendBounds([11,130],'nearestPower',10.,expected=[10,1000]) and passed\n",
    "passed = test_extendBounds([-11,130],'nearestPower',10,expected=[-100,1000]) and passed\n",
    "passed = test_extendBounds([-5100,-130],'nearestPower',10,expected=[-10000,-100]) and passed\n",
    "passed = test_extendBounds([-.0101,-0.00042],'nearestPower',10,expected=[-0.1,-0.0001]) and passed\n",
    "passed = test_extendBounds([0,0.00042],'nearestPower',10,expected=[0,0.001]) and passed\n",
    "print()\n",
    "\n",
    "print(\"Testing method 'nearestMultiple'\")\n",
    "print(\"  Expect errors:\")\n",
    "passed = test_extendBounds([11,132],'nearestMultiple',-2,expected=None) and passed\n",
    "passed = test_extendBounds([11,132],'nearestMultiple',0,expected=None) and passed\n",
    "passed = test_extendBounds([0,-10],'nearestMultiple',100,expected=None) and passed\n",
    "print(\"  Expect success:\")\n",
    "passed = test_extendBounds([11,132],'nearestMultiple',expected=[10,140]) and passed\n",
    "passed = test_extendBounds([10,130],'nearestMultiple',expected=[10,130]) and passed\n",
    "passed = test_extendBounds([11.55,132.55],'nearestMultiple',0.1,expected=[11.5,132.6]) and passed\n",
    "passed = test_extendBounds([11.55,132.55],'nearestMultiple',1,expected=[11,133]) and passed\n",
    "passed = test_extendBounds([11.55,132.55],'nearestMultiple',100,expected=[0,200]) and passed\n",
    "passed = test_extendBounds([-11,132],'nearestMultiple',10,expected=[-20,140]) and passed\n",
    "passed = test_extendBounds([-1121,-132],'nearestMultiple',10,expected=[-1130,-130]) and passed\n",
    "passed = test_extendBounds([-10,-10],'nearestMultiple',10,expected=[-10,-10]) and passed\n",
    "passed = test_extendBounds([-10,-10],'nearestMultiple',100,expected=[-100,0]) and passed\n",
    "print()\n",
    "\n",
    "print(\"Testing method 'round'\")\n",
    "print(\"  Expect errors:\")\n",
    "passed = test_extendBounds([-11.1,-132.1],'round',expected=None) and passed\n",
    "print(\"  Expect success:\")\n",
    "passed = test_extendBounds([11.1,132.1],'round',expected=[11,133]) and passed\n",
    "passed = test_extendBounds([10,130],'round',expected=[10,130]) and passed\n",
    "passed = test_extendBounds([11.1,132.1],'round',-2,expected=[11,133]) and passed\n",
    "passed = test_extendBounds([-11.1,132.1],'round',expected=[-12,133]) and passed\n",
    "passed = test_extendBounds([-1100.1,-132.1],'round',expected=[-1101,-132]) and passed\n",
    "print()\n",
    "\n",
    "print(\"Testing array execution\")\n",
    "print(\"  Expect errors:\")\n",
    "print(\"  Expect success:\")\n",
    "print(\"    method\")\n",
    "passed = test_extendBound(1.5,'up','nearestLeadingDigit',4,expected=2) and passed\n",
    "passed = test_extendBound(1.5,'up','nearestPower',4,expected=4) and passed\n",
    "passed = test_extendBound(1.5,'up','nearestMultiple',4,expected=4) and passed\n",
    "passed = test_extendBound(1.5,'up','round',4,expected=2) and passed\n",
    "print(\"    direction\")\n",
    "passed = test_extendBound(1.5,'up','nearestMultiple',4,expected=4) and passed\n",
    "passed = test_extendBound(1.5,0.1,'nearestMultiple',4,expected=4) and passed\n",
    "passed = test_extendBound(1.5,'down','nearestMultiple',4,expected=0) and passed\n",
    "passed = test_extendBound(1.5,-0.1,'nearestMultiple',4,expected=0) and passed\n",
    "print(\"    broadcasting\")\n",
    "passed = test_extendBound([1.5],'up','nearestMultiple',1,expected=[2]) and passed\n",
    "passed = test_extendBound([1.5,2.5],'up','nearestMultiple',1,expected=[2,3]) and passed\n",
    "passed = test_extendBound(1.5,['up','down'],'nearestMultiple',1,expected=[2,1]) and passed\n",
    "passed = test_extendBound(1.5,'up',['nearestLeadingDigit','nearestPower','nearestMultiple','round'],3,expected=[2,3,3,2]) and passed\n",
    "passed = test_extendBound(1.5,'up','nearestMultiple',[1,5,10],expected=[2,5,10]) and passed\n",
    "print()\n",
    "\n",
    "print(\"All tests passed:\",passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc82d7",
   "metadata": {},
   "source": [
    "## Import using GeoPandas\n",
    "\n",
    "Earlier version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877bdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMLtoGDF(filename):\n",
    "    gdf = geopandas.read_file(filename)\n",
    "    gdf.rename_geometry('Geometry', inplace=True) # Default geometry column name is 'geometry'; changed for consistent capitalization of columns\n",
    "    gdf.set_geometry('Geometry') # Renaming is insufficient; this sets special variable gdf.geometry = gdf['Geometry']\n",
    "    gdf = gdf.set_crs(epsg=3347) # Needed only for FSA file, the others are 3347 and parsed correctly by geopandas, and the pdf in the zip file has the same projection parameters (FSA vs. DA, ADA, CT)\n",
    "    gdf['Area'] = gdf['Geometry'].to_crs(epsg=6931).area # Equal-area projection # MODIFY THIS to account for validity regions of each geometry\n",
    "    gdf['Centroid'] = gdf['Geometry'].centroid\n",
    "    gdf['Geometry'] = gdf['Geometry'].to_crs(epsg=4326) # Latitude/Longitude representation\n",
    "    gdf['Centroid'] = gdf['Centroid'].to_crs(epsg=4326) # Only the set geometry is converted with gdf.to_crs(); all other geometry-containing columns must be converted explicitly; here we convert all columns explicitly\n",
    "    gdf = gdf.set_crs(epsg=4326) # The series and geodataframe can have separate crs; this was found necessary for the geopandas.union function to operate easily\n",
    "    gdf['Centroid Latitude'] = gdf['Centroid'].geometry.y\n",
    "    gdf['Centroid Longitude'] = gdf['Centroid'].geometry.x\n",
    "    gdf.drop(columns = 'Centroid', inplace=True) # Because WKT Point cannot be serialized to JSON, we drop the Centroid column and keep only its float components\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa577ea",
   "metadata": {},
   "source": [
    "Modified with comments; use standard 'geometry' instead of 'Geometry', preserve original crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69171743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMLtoGDF(filename):\n",
    "    gdf = geopandas.read_file(filename)\n",
    "    #gdf.rename_geometry('Geometry', inplace=True) # Removed to revert to standard geopandas naming 'geometry' # Default geometry column name is 'geometry'; changed for consistent capitalization of columns\n",
    "    #gdf.set_geometry('Geometry') # Removed to revert to standard geopandas naming 'geometry' # Renaming is insufficient; this sets special variable gdf.geometry = gdf['Geometry']\n",
    "    gdf = gdf.set_crs(epsg=3347) # Needed only for FSA file, the others are 3347 and parsed correctly by geopandas, and the pdf in the zip file has the same projection parameters (FSA vs. DA, ADA, CT)\n",
    "    gdf['Area'] = gdf.geometry.to_crs(epsg=6931).area # Equal-area projection # MODIFY THIS to account for validity regions of each geometry\n",
    "    gdf['Centroid'] = gdf.geometry.centroid\n",
    "    #gdf['Geometry'] = gdf.geometry.to_crs(epsg=4326) # Removed to preserve original crs # Latitude/Longitude representation\n",
    "    gdf['Centroid'] = gdf['Centroid'].to_crs(epsg=4326) # Only the set geometry is converted with gdf.to_crs(); all other geometry-containing columns must be converted explicitly; here we convert all columns explicitly\n",
    "    #gdf = gdf.set_crs(epsg=4326) # Removed to preserve original crs # The series and geodataframe can have separate crs; this was found necessary for the geopandas.union function to operate easily\n",
    "    gdf['Centroid Latitude'] = gdf['Centroid'].geometry.y\n",
    "    gdf['Centroid Longitude'] = gdf['Centroid'].geometry.x\n",
    "    gdf.drop(columns = 'Centroid', inplace=True) # Because WKT Point cannot be serialized to JSON, we drop the Centroid column and keep only its float components\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a61ba6",
   "metadata": {},
   "source": [
    "Final version without comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48475c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMLtoGDF(filename):\n",
    "    gdf = geopandas.read_file(filename)\n",
    "    gdf = gdf.set_crs(epsg=3347) # Needed only for FSA file, the others are 3347 and parsed correctly by geopandas, and the pdf in the zip file has the same projection parameters (FSA vs. DA, ADA, CT)\n",
    "    gdf['Area'] = gdf.geometry.to_crs(epsg=6931).area # Equal-area projection # MODIFY THIS to account for validity regions of each geometry\n",
    "    gdf['Centroid'] = gdf.geometry.centroid\n",
    "    gdf['Centroid'] = gdf['Centroid'].to_crs(epsg=4326) # Only the set geometry is converted with gdf.to_crs(); all other geometry-containing columns must be converted explicitly; here we convert all columns explicitly\n",
    "    gdf['Centroid Latitude'] = gdf['Centroid'].geometry.y\n",
    "    gdf['Centroid Longitude'] = gdf['Centroid'].geometry.x\n",
    "    gdf.drop(columns = 'Centroid', inplace=True) # Because WKT Point cannot be serialized to JSON, we drop the Centroid column and keep only its float components\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf2ec3",
   "metadata": {},
   "source": [
    "## Save/Load (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "385a70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function(s) to encapsulate loading and saving long calculations\n",
    "def loadResults_(name,tuples,fileformat='db',compress=False):\n",
    "    '''Loads variables from files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str, file name base (including directory if desired)\n",
    "    tuples: list of tuples (varname, suffix),\n",
    "        varname: str, the key of the output dict where the data will be stored\n",
    "        suffix: str, the string appended to name to generate a full file name\n",
    "    fileformat: str, suffix to save the file with (do not include period)\n",
    "    compress: bool, True to zip results (appends '.gz' to filename)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None if an error was encountered, or\n",
    "    Tuple the length of tuples containing for each element of tuples:\n",
    "        None if there was an error, or\n",
    "        the variable loaded from file at the same position from tuples\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Files read in binary format with optional gzip encoding\n",
    "    This function is the complement to saveResults_()\n",
    "    \n",
    "    TODO\n",
    "    ----\n",
    "    Add option to change save format (text vs. binary)\n",
    "    Make fileformat select the save format\n",
    "    '''\n",
    "    if type(name)!=str:\n",
    "        print('Error: name must be a string')\n",
    "        return None\n",
    "    if type(fileformat)!=str:\n",
    "        print('Error: fileformat must be a string')\n",
    "        return None\n",
    "    \n",
    "    ret = []\n",
    "    for n, s in tuples:\n",
    "        fn = name+s+'.'+fileformat+('.gz' if compress else '')\n",
    "        try:\n",
    "            with open(fn,'rb') as file:\n",
    "                ret.append(dill.loads(gzip.decompress(file.read()) if compress else file.read()))\n",
    "        except (FileNotFoundError, IOError) as e:\n",
    "            ret.append(None)\n",
    "            print(f'An error was encountered while reading from file {fn}: {e}')\n",
    "    return tuple(ret)\n",
    "\n",
    "def loadResults(name):\n",
    "    '''Loads variables 'gdf_union', 'times', and 'areas' from zipped files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str containing the base name of the files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None if an error was encountered, or\n",
    "    Tuple the length of tuples containing:\n",
    "        None if there was an error, or\n",
    "        the variable loaded from file at the same position from tuples\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    File names area <name>_<variable>.db.gz and are in gzip dill binary format\n",
    "    Uses outside variable DIR_RESULTS if available, otherwise put path in name\n",
    "    '''\n",
    "    tuples = [('gdf_union',''),\n",
    "              ('times','_times'),\n",
    "              ('areas','_areas')]\n",
    "    \n",
    "    return loadResults_(name,tuples,fileformat='db',compress=True)\n",
    "\n",
    "def saveResults_(name,tuples,fileformat='db',compress=False):\n",
    "    '''Saves variables to files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str, file name base (including directory if desired)\n",
    "    tuples: list of tuples (varname, suffix),\n",
    "        var: <any>, the variable to be output to file\n",
    "        suffix: str, the string appended to name to generate a full file name\n",
    "    fileformat: str, suffix to save the file with (do not include period)\n",
    "    compress: bool, True to zip results (appends '.gz' to filename)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None if an error was encountered, or\n",
    "    Tuple the same length as tuples containing return codes:\n",
    "        0 Failure\n",
    "        1 Success\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Files written in binary format\n",
    "    Files are created if they do not already exist\n",
    "    Files are overwritten if they already exist\n",
    "\n",
    "    TODO\n",
    "    ----\n",
    "    Make fileformat determine save format\n",
    "\n",
    "    '''\n",
    "    if type(name)!=str:\n",
    "        print('Error: name must be a string')\n",
    "        return None\n",
    "    if type(fileformat)!=str:\n",
    "        print('Error: fileformat must be a string')\n",
    "        return None\n",
    "    \n",
    "    ret = []\n",
    "    for v, s in tuples:\n",
    "        fn = name+s+'.'+fileformat+('.gz' if compress else '')\n",
    "        try:\n",
    "            with open(fn,'wb+') as file:\n",
    "                file.write(gzip.compress(dill.dumps(v)) if compress else dill.dumps(v))\n",
    "                ret.append(1)\n",
    "        except IOError as e:\n",
    "            ret.append(0)\n",
    "            print(f'An error was encountered while writing to file {fn}: {e}')\n",
    "    return tuple(ret)\n",
    "\n",
    "def saveResults(name, gdf_union, times, areas):\n",
    "    '''Saves variables 'times', 'areas', and 'gdf_union' to zipped files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str, file name base (including directory if desired)\n",
    "    gdf_union: geodataframe of geographic areas, produced from intersectGDF()\n",
    "    times: 1d array of computation times, produced from intersectGDF()\n",
    "    areas: list of lists of overlap areas, produced from intersectGDF()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None if an error was encountered, or\n",
    "    Tuple the same length as tuples containing return codes:\n",
    "        0 Failure\n",
    "        1 Success\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    File names area <name><variable>.db.gz and are in gzip dill binary format\n",
    "    Use outside variable DIR_RESULTS in construction of name\n",
    "    '''\n",
    "    tuples = [(gdf_union,''),\n",
    "              (times,'_times'),\n",
    "              (areas,'_areas')]\n",
    "    \n",
    "    return saveResults_(name,tuples,fileformat='db',compress=True)\n",
    "\n",
    "def loadComputeSave(gdf1, key1, gdf2, key2, loadname=None, savename=None, verbosity=1, area_epsg=6931, gdf1b=None, gdf2b=None):\n",
    "    '''Returns the overlap of geometries, defaulting to file versions if possible\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf_1: GeoDataFrame (must match crs of gdf2, will be utilized for vectorized overlap calculation)\n",
    "    keyfield1: column name in gdf1 which uniquely identifies each row and will be used to label the results\n",
    "    gdf2: GeoDataFrame (must match crs of gdf1, will be iterated over for overlap calculation)\n",
    "    keyfield2: column name in gdf2 which uniquely identifies each row and will be used to label the results\n",
    "    loadname: str or None, base name of files to load data from (None -> 'DEFAULT'), see saveResults()\n",
    "    savename: str or None, base name of files to save data to (None -> loadname), see loadResults()\n",
    "    verbosity: int, detail level of reporting during execution: 0=none, 1=10-100 updates, 2=update every loop and announce exceptions\n",
    "    area_epsg: int, convert to this epsg for area calculation\n",
    "    gdf1b: gdf1 with all geometries valid, to be used in case of failed overlap with gdf1, if None use gdf1.buffer(0)\n",
    "    gdf2b: gdf2 with all geometries valid, to be used in case of failed overlap with gdf2, if None use gdf2.buffer(0)\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    gdf_union: Geodataframe containing columns of nonzero overlap geometries, corresponding gdf1[keyfield1], and corresponding gdf2[keyfield2], where only one value of gdf1[keyfield1] is selected which is the one with maximum overlap area\n",
    "    times: List of execution times for each overlap calculation; len(times)=gdf2.shape[0]\n",
    "    areas: List of pandas Series of overlap areas; len(areas)=gdf2.shape[0], len(areas[i])=gdf1.shape[0]\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    gdf1 and gdf2 must be set to the same crs\n",
    "    Iterates over gdf2, which should have the larger number of rows of {gdf1,gdf2} in order to minimize required memory (assuming geometries are of roughly equal size)\n",
    "    '''\n",
    "    verbosity = 1\n",
    "    \n",
    "    if savename is None:\n",
    "        savename = loadname if not loadname is None else 'DEFAULT'\n",
    "    \n",
    "    ret = None if loadname is None else loadResults(DIR_RESULTS+loadname)\n",
    "    recompute = False\n",
    "    saveresults = False\n",
    "    if ret is None:\n",
    "        recompute = True\n",
    "        saveresults = True\n",
    "    else:\n",
    "        gdf_union, times, areas = ret\n",
    "        if gdf_union is None:\n",
    "            if areas is None: # Recompute\n",
    "                recompute = True\n",
    "                saveresults = True\n",
    "            else:                # Reconstruct from areas\n",
    "                print(\"Overlaps will be recomputed based on loaded variable 'areas'\")\n",
    "                gdf_union, times, areas = intersectGDF(gdf1,key1,gdf2,key2,areas_in=temp_areas,verbosity=1)\n",
    "                saveresults = True\n",
    "        else:\n",
    "            print(\"Overlaps loaded from file\")\n",
    "\n",
    "    if recompute:\n",
    "        print(\"Overlaps must be computed\")\n",
    "        gdf_union, times, areas = intersectGDF(gdf1,key1,gdf2,key2,verbosity=1)\n",
    "    \n",
    "    if saveresults:\n",
    "        saveResults(DIR_RESULTS+savename, gdf_union, times, areas)\n",
    "        print(\"Variables saved to file at \"+DIR_RESULTS+savename)\n",
    "\n",
    "    return gdf_union, times, areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30031be",
   "metadata": {},
   "source": [
    "### Save/Load new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4420b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7875d1c",
   "metadata": {},
   "source": [
    "## mapCitiesAdjacent Old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a810cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapCitiesAdjacent(cities,propertyname,title='',tooltiplabels=None):\n",
    "    '''Displays cities in separate adjacent maps\n",
    "    \n",
    "    Cities dict as above\n",
    "    Displayed as choropleth keyed to propertyname\n",
    "    Header displays title and colormap labeled with keyed propertyname\n",
    "    Tooltips pop up on mouseover showing properties listed in tooltiplabels\n",
    "    \n",
    "    Inspired by https://gitter.im/python-visualization/folium?at=5a36090a03838b2f2a04649d\n",
    "    \n",
    "    Assumes propertyname is identical in gdf and geojson\n",
    "    '''\n",
    "    if (not type(cities)==list) and type(cities)==dict:\n",
    "        cities = [cities]\n",
    "    \n",
    "    f = bre.Figure()\n",
    "    div_header = bre.Div(position='absolute',height='10%',width='100%',left='0%',top='0%').add_to(f)\n",
    "\n",
    "    map_header = folium.Map(location=[0,0],control_scale=False,zoom_control=False,tiles=None,attr=False).add_to(div_header)\n",
    "    div_header2 = bre.Div(position='absolute',height='10%',width='97%',left='3%',top='0%').add_to(div_header)\n",
    "    html_header = '''<h3 align=\"left\" style=\"font-size:16px;charset=utf-8\"><b>{}</b></h3>'''.format(title)\n",
    "    div_header2.get_root().html.add_child(folium.Element(html_header))\n",
    "\n",
    "    vbounds = getCityBounds(cities,propertyname)\n",
    "    vbounds[0] = 0\n",
    "    vbounds = extendBounds(vbounds,'nearestLeadingDigit')\n",
    "    \n",
    "    cm_header = LinearColormap(\n",
    "        colors=['yellow', 'orange', 'red'],\n",
    "        index=None,\n",
    "        vmin=vbounds[0],\n",
    "        vmax=vbounds[1],\n",
    "        caption=propertyname\n",
    "        ).add_to(map_header) # .to_step(method='log', n=5, data=?), log has log labels but linear color scale\n",
    "\n",
    "    for i, city in enumerate(cities):\n",
    "        div_map = bre.Div(position='absolute',height='80%',width=f'{(100/len(cities))}%',left=f'{(i*100/len(cities))}%',top='10%').add_to(f)\n",
    "\n",
    "        city_map = folium.Map(location=city['centroid'], control_scale=True)\n",
    "        div_map.add_child(city_map)\n",
    "        title_html = '''<h3 align=\"center\" style=\"font-size:16px;charset=utf-8\"><b>{}</b></h3>'''.format(city['name'])\n",
    "        city_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "        city_map.fit_bounds(city['bounds'])\n",
    "\n",
    "        m = folium.GeoJson(\n",
    "                    city['geojson'],\n",
    "                    style_function=lambda feature: {\n",
    "                        'fillColor': cm_header.rgb_hex_str(feature['properties'][propertyname]),\n",
    "                        'fillOpacity': 0.8,\n",
    "                        'color':'black',\n",
    "                        'weight': 1,\n",
    "                        'opacity': 0.2,\n",
    "                    },\n",
    "                    name=f'Choropleth_{i}'\n",
    "                ).add_to(city_map)\n",
    "        if not tooltiplabels==None:\n",
    "            m.add_child(folium.features.GeoJsonTooltip(tooltiplabels))\n",
    "    \n",
    "    return display(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
